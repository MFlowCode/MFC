<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>MFC:Post_process: m_mpi_proxy Module Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">MFC:Post_process
   &#160;<span id="projectnumber">v1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('namespacem__mpi__proxy.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#func-members">Functions/Subroutines</a>  </div>
  <div class="headertitle">
<div class="title">m_mpi_proxy Module Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>This module serves as a proxy to the parameters and subroutines available in the MPI implementation's MPI module. Specifically, the role of the proxy is to harness basic MPI commands into more complex procedures as to achieve the required communication goals for the post-process.  
<a href="#details">More...</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions/Subroutines</h2></td></tr>
<tr class="memitem:a9bc4c617505152d3cc553e5bc25c1ee1"><td class="memItemLeft" align="right" valign="top">subroutine&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacem__mpi__proxy.html#a9bc4c617505152d3cc553e5bc25c1ee1">s_mpi_initialize</a> ()</td></tr>
<tr class="memdesc:a9bc4c617505152d3cc553e5bc25c1ee1"><td class="mdescLeft">&#160;</td><td class="mdescRight">The subroutine intializes the MPI environment and queries both the number of processors that will be available for the job as well as the local processor rank.  <a href="#a9bc4c617505152d3cc553e5bc25c1ee1">More...</a><br /></td></tr>
<tr class="separator:a9bc4c617505152d3cc553e5bc25c1ee1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a04ac565bad2b22dc045a5eeb4f516e2e"><td class="memItemLeft" align="right" valign="top">subroutine&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacem__mpi__proxy.html#a04ac565bad2b22dc045a5eeb4f516e2e">s_mpi_abort</a> ()</td></tr>
<tr class="memdesc:a04ac565bad2b22dc045a5eeb4f516e2e"><td class="mdescLeft">&#160;</td><td class="mdescRight">The subroutine terminates the MPI execution environment.  <a href="#a04ac565bad2b22dc045a5eeb4f516e2e">More...</a><br /></td></tr>
<tr class="separator:a04ac565bad2b22dc045a5eeb4f516e2e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr><td colspan="2"><div class="groupHeader">q_cons_vf Conservative variables</div></td></tr>
<tr><td colspan="2"><div class="groupText"><p>This subroutine defines local and global sizes for the data </p>
</div></td></tr>
<tr class="memitem:a2ff35ede51e90c483969e44c31303415"><td class="memItemLeft" align="right" valign="top">subroutine&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacem__mpi__proxy.html#a2ff35ede51e90c483969e44c31303415">s_initialize_mpi_data</a> (q_cons_vf)</td></tr>
<tr class="separator:a2ff35ede51e90c483969e44c31303415"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abfbc42cea69273bc9fa4a2d78f636eb1"><td class="memItemLeft" align="right" valign="top">subroutine&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacem__mpi__proxy.html#abfbc42cea69273bc9fa4a2d78f636eb1">s_mpi_barrier</a> ()</td></tr>
<tr class="memdesc:abfbc42cea69273bc9fa4a2d78f636eb1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Halts all processes until all have reached barrier.  <a href="#abfbc42cea69273bc9fa4a2d78f636eb1">More...</a><br /></td></tr>
<tr class="separator:abfbc42cea69273bc9fa4a2d78f636eb1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a015ee2c0892e9cfcb858da8f27b646d5"><td class="memItemLeft" align="right" valign="top">subroutine&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacem__mpi__proxy.html#a015ee2c0892e9cfcb858da8f27b646d5">s_initialize_mpi_proxy_module</a> ()</td></tr>
<tr class="memdesc:a015ee2c0892e9cfcb858da8f27b646d5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computation of parameters, allocation procedures, and/or any other tasks needed to properly setup the module.  <a href="#a015ee2c0892e9cfcb858da8f27b646d5">More...</a><br /></td></tr>
<tr class="separator:a015ee2c0892e9cfcb858da8f27b646d5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a69660c5fe9302a8c0496b622fa3b5286"><td class="memItemLeft" align="right" valign="top">subroutine&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacem__mpi__proxy.html#a69660c5fe9302a8c0496b622fa3b5286">s_mpi_bcast_user_inputs</a> ()</td></tr>
<tr class="memdesc:a69660c5fe9302a8c0496b622fa3b5286"><td class="mdescLeft">&#160;</td><td class="mdescRight">Since only processor with rank 0 is in charge of reading and checking the consistency of the user provided inputs, these are not available to the remaining processors. This subroutine is then in charge of broadcasting the required information.  <a href="#a69660c5fe9302a8c0496b622fa3b5286">More...</a><br /></td></tr>
<tr class="separator:a69660c5fe9302a8c0496b622fa3b5286"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a80c5e235786545276fe6ffa06965017f"><td class="memItemLeft" align="right" valign="top">subroutine&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacem__mpi__proxy.html#a80c5e235786545276fe6ffa06965017f">s_mpi_decompose_computational_domain</a> ()</td></tr>
<tr class="memdesc:a80c5e235786545276fe6ffa06965017f"><td class="mdescLeft">&#160;</td><td class="mdescRight">This subroutine takes care of efficiently distributing the computational domain among the available processors as well as recomputing some of the global parameters so that they reflect the configuration of sub-domain that is overseen by the local processor.  <a href="#a80c5e235786545276fe6ffa06965017f">More...</a><br /></td></tr>
<tr class="separator:a80c5e235786545276fe6ffa06965017f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e48d59a04981a6594f25ad7a7562492"><td class="memItemLeft" align="right" valign="top">subroutine&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacem__mpi__proxy.html#a8e48d59a04981a6594f25ad7a7562492">s_mpi_sendrecv_grid_vars_buffer_regions</a> (pbc_loc, sweep_coord)</td></tr>
<tr class="memdesc:a8e48d59a04981a6594f25ad7a7562492"><td class="mdescLeft">&#160;</td><td class="mdescRight">Communicates the buffer regions associated with the grid variables with processors in charge of the neighbooring sub-domains. Note that only cell-width spacings feature buffer regions so that no information relating to the cell-boundary locations is communicated.  <a href="#a8e48d59a04981a6594f25ad7a7562492">More...</a><br /></td></tr>
<tr class="separator:a8e48d59a04981a6594f25ad7a7562492"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4d7ec0d1976967504babdf44ec83c1b1"><td class="memItemLeft" align="right" valign="top">subroutine&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacem__mpi__proxy.html#a4d7ec0d1976967504babdf44ec83c1b1">s_mpi_sendrecv_cons_vars_buffer_regions</a> (q_cons_vf, pbc_loc, sweep_coord)</td></tr>
<tr class="memdesc:a4d7ec0d1976967504babdf44ec83c1b1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Communicates buffer regions associated with conservative variables with processors in charge of the neighbooring sub-domains.  <a href="#a4d7ec0d1976967504babdf44ec83c1b1">More...</a><br /></td></tr>
<tr class="separator:a4d7ec0d1976967504babdf44ec83c1b1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adaa028bb99f844487de8d6e4507e7734"><td class="memItemLeft" align="right" valign="top">subroutine&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacem__mpi__proxy.html#adaa028bb99f844487de8d6e4507e7734">s_mpi_reduce_maxloc</a> (var_loc)</td></tr>
<tr class="memdesc:adaa028bb99f844487de8d6e4507e7734"><td class="mdescLeft">&#160;</td><td class="mdescRight">The following subroutine takes the first element of the 2-element inputted variable and determines its maximum value on the entire computational domain. The result is stored back into the first element of the variable while the rank of the processor that is in charge of the sub- domain containing the maximum is stored into the second element of the variable.  <a href="#adaa028bb99f844487de8d6e4507e7734">More...</a><br /></td></tr>
<tr class="separator:adaa028bb99f844487de8d6e4507e7734"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab2ced8f095b812fcc355539c2c5fa162"><td class="memItemLeft" align="right" valign="top">subroutine&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacem__mpi__proxy.html#ab2ced8f095b812fcc355539c2c5fa162">s_mpi_gather_spatial_extents</a> (spatial_extents)</td></tr>
<tr class="memdesc:ab2ced8f095b812fcc355539c2c5fa162"><td class="mdescLeft">&#160;</td><td class="mdescRight">This subroutine gathers the Silo database metadata for the spatial extents in order to boost the performance of the multidimensional visualization.  <a href="#ab2ced8f095b812fcc355539c2c5fa162">More...</a><br /></td></tr>
<tr class="separator:ab2ced8f095b812fcc355539c2c5fa162"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac15a15ba12e6110bb015af0ece5bba47"><td class="memItemLeft" align="right" valign="top">subroutine&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacem__mpi__proxy.html#ac15a15ba12e6110bb015af0ece5bba47">s_mpi_defragment_1d_grid_variable</a> ()</td></tr>
<tr class="memdesc:ac15a15ba12e6110bb015af0ece5bba47"><td class="mdescLeft">&#160;</td><td class="mdescRight">This subroutine collects the sub-domain cell-boundary or cell-center locations data from all of the processors and puts back together the grid of the entire computational domain on the rank 0 processor. This is only done for 1D simulations.  <a href="#ac15a15ba12e6110bb015af0ece5bba47">More...</a><br /></td></tr>
<tr class="separator:ac15a15ba12e6110bb015af0ece5bba47"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b226acd5a9097566685604292c3ae0d"><td class="memItemLeft" align="right" valign="top">subroutine&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacem__mpi__proxy.html#a0b226acd5a9097566685604292c3ae0d">s_mpi_gather_data_extents</a> (q_sf, data_extents)</td></tr>
<tr class="memdesc:a0b226acd5a9097566685604292c3ae0d"><td class="mdescLeft">&#160;</td><td class="mdescRight">This subroutine gathers the Silo database metadata for the flow variable's extents as to boost performance of the multidimensional visualization.  <a href="#a0b226acd5a9097566685604292c3ae0d">More...</a><br /></td></tr>
<tr class="separator:a0b226acd5a9097566685604292c3ae0d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae5286531f6390643aad1e4db5d5f6d91"><td class="memItemLeft" align="right" valign="top">subroutine&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacem__mpi__proxy.html#ae5286531f6390643aad1e4db5d5f6d91">s_mpi_defragment_1d_flow_variable</a> (q_sf, q_root_sf)</td></tr>
<tr class="memdesc:ae5286531f6390643aad1e4db5d5f6d91"><td class="mdescLeft">&#160;</td><td class="mdescRight">This subroutine gathers the sub-domain flow variable data from all of the processors and puts it back together for the entire computational domain on the rank 0 processor. This is only done for 1D simulations.  <a href="#ae5286531f6390643aad1e4db5d5f6d91">More...</a><br /></td></tr>
<tr class="separator:ae5286531f6390643aad1e4db5d5f6d91"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac984c84fe4140876d6600250af9807da"><td class="memItemLeft" align="right" valign="top">subroutine&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacem__mpi__proxy.html#ac984c84fe4140876d6600250af9807da">s_finalize_mpi_proxy_module</a> ()</td></tr>
<tr class="memdesc:ac984c84fe4140876d6600250af9807da"><td class="mdescLeft">&#160;</td><td class="mdescRight">Deallocation procedures for the module.  <a href="#ac984c84fe4140876d6600250af9807da">More...</a><br /></td></tr>
<tr class="separator:ac984c84fe4140876d6600250af9807da"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a43fbda10c02ec8bc1fc572c83090f2e5"><td class="memItemLeft" align="right" valign="top">subroutine&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacem__mpi__proxy.html#a43fbda10c02ec8bc1fc572c83090f2e5">s_mpi_finalize</a> ()</td></tr>
<tr class="memdesc:a43fbda10c02ec8bc1fc572c83090f2e5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Finalization of all MPI related processes.  <a href="#a43fbda10c02ec8bc1fc572c83090f2e5">More...</a><br /></td></tr>
<tr class="separator:a43fbda10c02ec8bc1fc572c83090f2e5"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="var-members"></a>
Variables</h2></td></tr>
<tr><td colspan="2"><div class="groupHeader">Buffers of the conservative variables recieved/sent from/to neighbooring</div></td></tr>
<tr><td colspan="2"><div class="groupText"><p>processors. Note that these variables are structured as vectors rather than arrays. </p>
</div></td></tr>
<tr class="memitem:af08f3246d9efac15d6391dc4205d4611"><td class="memItemLeft" align="right" valign="top">real(kind(0d0)), dimension(:), allocatable&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacem__mpi__proxy.html#af08f3246d9efac15d6391dc4205d4611">q_cons_buffer_in</a></td></tr>
<tr class="separator:af08f3246d9efac15d6391dc4205d4611"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3d449655a88a9e5248af35a82caf877a"><td class="memItemLeft" align="right" valign="top">real(kind(0d0)), dimension(:), allocatable&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacem__mpi__proxy.html#a3d449655a88a9e5248af35a82caf877a">q_cons_buffer_out</a></td></tr>
<tr class="separator:a3d449655a88a9e5248af35a82caf877a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr><td colspan="2"><div class="groupHeader">Recieve counts and displacement vector variables, respectively, used in</div></td></tr>
<tr><td colspan="2"><div class="groupText"><p>enabling MPI to gather varying amounts of data from all processes to the root process </p>
</div></td></tr>
<tr class="memitem:a2198e825f0884d4ee9e96b6efdb69cee"><td class="memItemLeft" align="right" valign="top">integer, dimension(:), allocatable&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacem__mpi__proxy.html#a2198e825f0884d4ee9e96b6efdb69cee">recvcounts</a></td></tr>
<tr class="separator:a2198e825f0884d4ee9e96b6efdb69cee"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aebaa6e3cc66d2431c5fb49896d40d7e6"><td class="memItemLeft" align="right" valign="top">integer, dimension(:), allocatable&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacem__mpi__proxy.html#aebaa6e3cc66d2431c5fb49896d40d7e6">displs</a></td></tr>
<tr class="separator:aebaa6e3cc66d2431c5fb49896d40d7e6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr><td colspan="2"><div class="groupHeader">Generic flags used to identify and report MPI errors</div></td></tr>
<tr class="memitem:ae5709407e3600d19d79b183e409bb982"><td class="memItemLeft" align="right" valign="top">integer, private&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacem__mpi__proxy.html#ae5709407e3600d19d79b183e409bb982">err_code</a></td></tr>
<tr class="separator:ae5709407e3600d19d79b183e409bb982"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a306ba163b09cfc692125f2c0ba82ef8c"><td class="memItemLeft" align="right" valign="top">integer, private&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacem__mpi__proxy.html#a306ba163b09cfc692125f2c0ba82ef8c">ierr</a></td></tr>
<tr class="separator:a306ba163b09cfc692125f2c0ba82ef8c"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>This module serves as a proxy to the parameters and subroutines available in the MPI implementation's MPI module. Specifically, the role of the proxy is to harness basic MPI commands into more complex procedures as to achieve the required communication goals for the post-process. </p>
</div><h2 class="groupheader">Function/Subroutine Documentation</h2>
<a id="ac984c84fe4140876d6600250af9807da"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac984c84fe4140876d6600250af9807da">&#9670;&nbsp;</a></span>s_finalize_mpi_proxy_module()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">subroutine m_mpi_proxy::s_finalize_mpi_proxy_module </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Deallocation procedures for the module. </p>

<p class="definition">Definition at line <a class="el" href="m__mpi__proxy_8f90_source.html#l01871">1871</a> of file <a class="el" href="m__mpi__proxy_8f90_source.html">m_mpi_proxy.f90</a>.</p>

</div>
</div>
<a id="a2ff35ede51e90c483969e44c31303415"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2ff35ede51e90c483969e44c31303415">&#9670;&nbsp;</a></span>s_initialize_mpi_data()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">subroutine m_mpi_proxy::s_initialize_mpi_data </td>
          <td>(</td>
          <td class="paramtype">type(<a class="el" href="structm__derived__types_1_1scalar__field.html">scalar_field</a>), dimension(sys_size), intent(in)&#160;</td>
          <td class="paramname"><em>q_cons_vf</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="m__mpi__proxy_8f90_source.html#l00125">125</a> of file <a class="el" href="m__mpi__proxy_8f90_source.html">m_mpi_proxy.f90</a>.</p>

</div>
</div>
<a id="a015ee2c0892e9cfcb858da8f27b646d5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a015ee2c0892e9cfcb858da8f27b646d5">&#9670;&nbsp;</a></span>s_initialize_mpi_proxy_module()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">subroutine m_mpi_proxy::s_initialize_mpi_proxy_module </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computation of parameters, allocation procedures, and/or any other tasks needed to properly setup the module. </p>

<p class="definition">Definition at line <a class="el" href="m__mpi__proxy_8f90_source.html#l00175">175</a> of file <a class="el" href="m__mpi__proxy_8f90_source.html">m_mpi_proxy.f90</a>.</p>

</div>
</div>
<a id="a04ac565bad2b22dc045a5eeb4f516e2e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a04ac565bad2b22dc045a5eeb4f516e2e">&#9670;&nbsp;</a></span>s_mpi_abort()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">subroutine m_mpi_proxy::s_mpi_abort </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The subroutine terminates the MPI execution environment. </p>

<p class="definition">Definition at line <a class="el" href="m__mpi__proxy_8f90_source.html#l00113">113</a> of file <a class="el" href="m__mpi__proxy_8f90_source.html">m_mpi_proxy.f90</a>.</p>

</div>
</div>
<a id="abfbc42cea69273bc9fa4a2d78f636eb1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abfbc42cea69273bc9fa4a2d78f636eb1">&#9670;&nbsp;</a></span>s_mpi_barrier()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">subroutine m_mpi_proxy::s_mpi_barrier </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Halts all processes until all have reached barrier. </p>

<p class="definition">Definition at line <a class="el" href="m__mpi__proxy_8f90_source.html#l00164">164</a> of file <a class="el" href="m__mpi__proxy_8f90_source.html">m_mpi_proxy.f90</a>.</p>

</div>
</div>
<a id="a69660c5fe9302a8c0496b622fa3b5286"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a69660c5fe9302a8c0496b622fa3b5286">&#9670;&nbsp;</a></span>s_mpi_bcast_user_inputs()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">subroutine m_mpi_proxy::s_mpi_bcast_user_inputs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Since only processor with rank 0 is in charge of reading and checking the consistency of the user provided inputs, these are not available to the remaining processors. This subroutine is then in charge of broadcasting the required information. </p>

<p class="definition">Definition at line <a class="el" href="m__mpi__proxy_8f90_source.html#l00273">273</a> of file <a class="el" href="m__mpi__proxy_8f90_source.html">m_mpi_proxy.f90</a>.</p>

</div>
</div>
<a id="a80c5e235786545276fe6ffa06965017f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a80c5e235786545276fe6ffa06965017f">&#9670;&nbsp;</a></span>s_mpi_decompose_computational_domain()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">subroutine m_mpi_proxy::s_mpi_decompose_computational_domain </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This subroutine takes care of efficiently distributing the computational domain among the available processors as well as recomputing some of the global parameters so that they reflect the configuration of sub-domain that is overseen by the local processor. </p>

<p class="definition">Definition at line <a class="el" href="m__mpi__proxy_8f90_source.html#l00440">440</a> of file <a class="el" href="m__mpi__proxy_8f90_source.html">m_mpi_proxy.f90</a>.</p>

</div>
</div>
<a id="ae5286531f6390643aad1e4db5d5f6d91"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae5286531f6390643aad1e4db5d5f6d91">&#9670;&nbsp;</a></span>s_mpi_defragment_1d_flow_variable()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">subroutine m_mpi_proxy::s_mpi_defragment_1d_flow_variable </td>
          <td>(</td>
          <td class="paramtype">real(kind(0d0)), dimension(0:m,0:0,0:0), intent(in)&#160;</td>
          <td class="paramname"><em>q_sf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">real(kind(0d0)), dimension(0:m_root,0:0,0:0), intent(inout)&#160;</td>
          <td class="paramname"><em>q_root_sf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This subroutine gathers the sub-domain flow variable data from all of the processors and puts it back together for the entire computational domain on the rank 0 processor. This is only done for 1D simulations. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">q_sf</td><td>Flow variable defined on a single computational sub-domain </td></tr>
    <tr><td class="paramname">q_root_sf</td><td>Flow variable defined on the entire computational domain </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="m__mpi__proxy_8f90_source.html#l01847">1847</a> of file <a class="el" href="m__mpi__proxy_8f90_source.html">m_mpi_proxy.f90</a>.</p>

</div>
</div>
<a id="ac15a15ba12e6110bb015af0ece5bba47"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac15a15ba12e6110bb015af0ece5bba47">&#9670;&nbsp;</a></span>s_mpi_defragment_1d_grid_variable()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">subroutine m_mpi_proxy::s_mpi_defragment_1d_grid_variable </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This subroutine collects the sub-domain cell-boundary or cell-center locations data from all of the processors and puts back together the grid of the entire computational domain on the rank 0 processor. This is only done for 1D simulations. </p>

<p class="definition">Definition at line <a class="el" href="m__mpi__proxy_8f90_source.html#l01781">1781</a> of file <a class="el" href="m__mpi__proxy_8f90_source.html">m_mpi_proxy.f90</a>.</p>

</div>
</div>
<a id="a43fbda10c02ec8bc1fc572c83090f2e5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a43fbda10c02ec8bc1fc572c83090f2e5">&#9670;&nbsp;</a></span>s_mpi_finalize()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">subroutine m_mpi_proxy::s_mpi_finalize </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Finalization of all MPI related processes. </p>

<p class="definition">Definition at line <a class="el" href="m__mpi__proxy_8f90_source.html#l01894">1894</a> of file <a class="el" href="m__mpi__proxy_8f90_source.html">m_mpi_proxy.f90</a>.</p>

</div>
</div>
<a id="a0b226acd5a9097566685604292c3ae0d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0b226acd5a9097566685604292c3ae0d">&#9670;&nbsp;</a></span>s_mpi_gather_data_extents()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">subroutine m_mpi_proxy::s_mpi_gather_data_extents </td>
          <td>(</td>
          <td class="paramtype">real(kind(0d0)), dimension(:,:,:), intent(in)&#160;</td>
          <td class="paramname"><em>q_sf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">real(kind(0d0)), dimension(1:2,0:num_procs-1), intent(inout)&#160;</td>
          <td class="paramname"><em>data_extents</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This subroutine gathers the Silo database metadata for the flow variable's extents as to boost performance of the multidimensional visualization. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">q_sf</td><td>Flow variable defined on a single computational sub-domain </td></tr>
    <tr><td class="paramname">data_extents</td><td>The flow variable extents on each of the processor's sub-domain. First dimension of array corresponds to the former's minimum and maximum values, respectively, while second dimension corresponds to each processor's rank. </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="m__mpi__proxy_8f90_source.html#l01816">1816</a> of file <a class="el" href="m__mpi__proxy_8f90_source.html">m_mpi_proxy.f90</a>.</p>

</div>
</div>
<a id="ab2ced8f095b812fcc355539c2c5fa162"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab2ced8f095b812fcc355539c2c5fa162">&#9670;&nbsp;</a></span>s_mpi_gather_spatial_extents()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">subroutine m_mpi_proxy::s_mpi_gather_spatial_extents </td>
          <td>(</td>
          <td class="paramtype">real(kind(0d0)), dimension(1:,0:), intent(inout)&#160;</td>
          <td class="paramname"><em>spatial_extents</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This subroutine gathers the Silo database metadata for the spatial extents in order to boost the performance of the multidimensional visualization. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">spatial_extents</td><td>Spatial extents for each processor's sub-domain. First dimension corresponds to the minimum and maximum values, respectively, while the second dimension corresponds to the processor rank. </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="m__mpi__proxy_8f90_source.html#l01661">1661</a> of file <a class="el" href="m__mpi__proxy_8f90_source.html">m_mpi_proxy.f90</a>.</p>

</div>
</div>
<a id="a9bc4c617505152d3cc553e5bc25c1ee1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9bc4c617505152d3cc553e5bc25c1ee1">&#9670;&nbsp;</a></span>s_mpi_initialize()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">subroutine m_mpi_proxy::s_mpi_initialize </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The subroutine intializes the MPI environment and queries both the number of processors that will be available for the job as well as the local processor rank. </p>

<p class="definition">Definition at line <a class="el" href="m__mpi__proxy_8f90_source.html#l00084">84</a> of file <a class="el" href="m__mpi__proxy_8f90_source.html">m_mpi_proxy.f90</a>.</p>

</div>
</div>
<a id="adaa028bb99f844487de8d6e4507e7734"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adaa028bb99f844487de8d6e4507e7734">&#9670;&nbsp;</a></span>s_mpi_reduce_maxloc()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">subroutine m_mpi_proxy::s_mpi_reduce_maxloc </td>
          <td>(</td>
          <td class="paramtype">real(kind(0d0)), dimension(2), intent(inout)&#160;</td>
          <td class="paramname"><em>var_loc</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The following subroutine takes the first element of the 2-element inputted variable and determines its maximum value on the entire computational domain. The result is stored back into the first element of the variable while the rank of the processor that is in charge of the sub- domain containing the maximum is stored into the second element of the variable. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">var_loc</td><td>On input, this variable holds the local value and processor rank, which are to be reduced among all the processors in communicator. On output, this variable holds the maximum value, reduced amongst all of the local values, and the process rank to which the value belongs. </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="m__mpi__proxy_8f90_source.html#l01631">1631</a> of file <a class="el" href="m__mpi__proxy_8f90_source.html">m_mpi_proxy.f90</a>.</p>

</div>
</div>
<a id="a4d7ec0d1976967504babdf44ec83c1b1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4d7ec0d1976967504babdf44ec83c1b1">&#9670;&nbsp;</a></span>s_mpi_sendrecv_cons_vars_buffer_regions()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">subroutine m_mpi_proxy::s_mpi_sendrecv_cons_vars_buffer_regions </td>
          <td>(</td>
          <td class="paramtype">type(<a class="el" href="structm__derived__types_1_1scalar__field.html">scalar_field</a>), dimension(sys_size), intent(inout)&#160;</td>
          <td class="paramname"><em>q_cons_vf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">character(len = 3), intent(in)&#160;</td>
          <td class="paramname"><em>pbc_loc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">character, intent(in)&#160;</td>
          <td class="paramname"><em>sweep_coord</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Communicates buffer regions associated with conservative variables with processors in charge of the neighbooring sub-domains. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">q_cons_vf</td><td>Conservative variables </td></tr>
    <tr><td class="paramname">pbc_loc</td><td>Processor boundary condition (PBC) location </td></tr>
    <tr><td class="paramname">sweep_coord</td><td>Coordinate direction normal to the processor boundary </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="m__mpi__proxy_8f90_source.html#l01094">1094</a> of file <a class="el" href="m__mpi__proxy_8f90_source.html">m_mpi_proxy.f90</a>.</p>

</div>
</div>
<a id="a8e48d59a04981a6594f25ad7a7562492"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8e48d59a04981a6594f25ad7a7562492">&#9670;&nbsp;</a></span>s_mpi_sendrecv_grid_vars_buffer_regions()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">subroutine m_mpi_proxy::s_mpi_sendrecv_grid_vars_buffer_regions </td>
          <td>(</td>
          <td class="paramtype">character(len = 3), intent(in)&#160;</td>
          <td class="paramname"><em>pbc_loc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">character, intent(in)&#160;</td>
          <td class="paramname"><em>sweep_coord</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Communicates the buffer regions associated with the grid variables with processors in charge of the neighbooring sub-domains. Note that only cell-width spacings feature buffer regions so that no information relating to the cell-boundary locations is communicated. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">pbc_loc</td><td>Processor boundary condition (PBC) location </td></tr>
    <tr><td class="paramname">sweep_coord</td><td>Coordinate direction normal to the processor boundary </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="m__mpi__proxy_8f90_source.html#l00892">892</a> of file <a class="el" href="m__mpi__proxy_8f90_source.html">m_mpi_proxy.f90</a>.</p>

</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="aebaa6e3cc66d2431c5fb49896d40d7e6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aebaa6e3cc66d2431c5fb49896d40d7e6">&#9670;&nbsp;</a></span>displs</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">integer, dimension(:), allocatable m_mpi_proxy::displs</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="m__mpi__proxy_8f90_source.html#l00067">67</a> of file <a class="el" href="m__mpi__proxy_8f90_source.html">m_mpi_proxy.f90</a>.</p>

</div>
</div>
<a id="ae5709407e3600d19d79b183e409bb982"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae5709407e3600d19d79b183e409bb982">&#9670;&nbsp;</a></span>err_code</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">integer, private m_mpi_proxy::err_code</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="m__mpi__proxy_8f90_source.html#l00072">72</a> of file <a class="el" href="m__mpi__proxy_8f90_source.html">m_mpi_proxy.f90</a>.</p>

</div>
</div>
<a id="a306ba163b09cfc692125f2c0ba82ef8c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a306ba163b09cfc692125f2c0ba82ef8c">&#9670;&nbsp;</a></span>ierr</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">integer, private m_mpi_proxy::ierr</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="m__mpi__proxy_8f90_source.html#l00072">72</a> of file <a class="el" href="m__mpi__proxy_8f90_source.html">m_mpi_proxy.f90</a>.</p>

</div>
</div>
<a id="af08f3246d9efac15d6391dc4205d4611"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af08f3246d9efac15d6391dc4205d4611">&#9670;&nbsp;</a></span>q_cons_buffer_in</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">real(kind(0d0)), dimension(:), allocatable m_mpi_proxy::q_cons_buffer_in</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="m__mpi__proxy_8f90_source.html#l00058">58</a> of file <a class="el" href="m__mpi__proxy_8f90_source.html">m_mpi_proxy.f90</a>.</p>

</div>
</div>
<a id="a3d449655a88a9e5248af35a82caf877a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3d449655a88a9e5248af35a82caf877a">&#9670;&nbsp;</a></span>q_cons_buffer_out</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">real(kind(0d0)), dimension(:), allocatable m_mpi_proxy::q_cons_buffer_out</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="m__mpi__proxy_8f90_source.html#l00059">59</a> of file <a class="el" href="m__mpi__proxy_8f90_source.html">m_mpi_proxy.f90</a>.</p>

</div>
</div>
<a id="a2198e825f0884d4ee9e96b6efdb69cee"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2198e825f0884d4ee9e96b6efdb69cee">&#9670;&nbsp;</a></span>recvcounts</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">integer, dimension(:), allocatable m_mpi_proxy::recvcounts</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="m__mpi__proxy_8f90_source.html#l00066">66</a> of file <a class="el" href="m__mpi__proxy_8f90_source.html">m_mpi_proxy.f90</a>.</p>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespacem__mpi__proxy.html">m_mpi_proxy</a></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
